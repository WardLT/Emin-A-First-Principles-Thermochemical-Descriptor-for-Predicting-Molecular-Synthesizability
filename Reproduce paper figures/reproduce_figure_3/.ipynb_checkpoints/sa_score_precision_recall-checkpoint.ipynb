{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533cf922-3a2b-4163-b274-d2cf29f71794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba1319a-7f7c-4f1a-b53d-016ec6eec025",
   "metadata": {},
   "source": [
    "# read in qm9 data with sa score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "366fc12b-25ec-4bed-bdca-f655bbcf7eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/clean/qm9_w_scores_smiles_1.csv')\n",
    "\n",
    "ground_truth = data[data['smiles_1 sa_score'] != 'ERROR']['Reported']\n",
    "prediction = data[data['smiles_1 sa_score'] != 'ERROR']['smiles_1 sa_score'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5fc5e4-e742-4e8d-8f77-00cacc8c33cb",
   "metadata": {},
   "source": [
    "# define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "292edc33-7f00-4f99-8eb3-8ace1aacc8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(ground_truth, prediction_value, c):\n",
    "                   \n",
    "    ground_truth = 1*ground_truth # change bools to numbers\n",
    "    prediction = 1*(prediction_value <= c)\n",
    "\n",
    "    # count false positives\n",
    "    fp = np.sum((ground_truth == 0) & (prediction == 1))\n",
    "\n",
    "    # find false negatives\n",
    "    fn = np.sum((ground_truth == 1) & (prediction == 0))\n",
    "\n",
    "    # find true positives\n",
    "    tp = np.sum((ground_truth == 1) & (prediction == 1))\n",
    "\n",
    "    # find true negatives\n",
    "    tn = np.sum((ground_truth == 0) & (prediction == 0))\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    return precision, recall, tp, tn, fp, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30b95c-e099-4b83-9a74-3f52b396c986",
   "metadata": {},
   "source": [
    "# get precision and recalls as a function of cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bca926a-dcbb-4815-8c7b-5cec1c5bfe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_list = []\n",
    "recall_list = []\n",
    "tp_list = []\n",
    "tn_list = []\n",
    "fp_list = []\n",
    "fn_list = []\n",
    "\n",
    "cutoffs = np.arange(1,10,0.01) # these are Emin cutoffs (not to be confused with synthesizabiloty) - units are in Ha\n",
    "\n",
    "for c in cutoffs:\n",
    "    \n",
    "    # for predictions on the validation data points\n",
    "    precision, recall, tp, tn, fp, fn = get_accuracies(ground_truth, prediction,c)\n",
    "    \n",
    "    precision_list += [precision]\n",
    "    recall_list += [recall]\n",
    "    tp_list += [tp]\n",
    "    tn_list += [tn]\n",
    "    fp_list += [fp]\n",
    "    fn_list += [fn]\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "precision_recalls = pd.DataFrame(data={'Cutoff': cutoffs,\n",
    "                                        'Precision': precision_list,\n",
    "                                        'Recall': recall_list,\n",
    "                                      'TP': tp_list,\n",
    "                                      'TN': tn_list,\n",
    "                                      'FP': fp_list,\n",
    "                                      'FN': fn_list})\n",
    "\n",
    "precision_recalls.to_csv(f'outputs/sa_score_precision_recall_roc_smiles_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
