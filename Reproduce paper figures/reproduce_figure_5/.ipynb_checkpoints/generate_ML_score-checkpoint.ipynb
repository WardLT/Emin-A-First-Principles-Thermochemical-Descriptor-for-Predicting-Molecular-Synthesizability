{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a quick and simple ML model that predicts the synthesizability of materials using Mordred features, SA score, and Emin as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data with qm9 energies, SA scores, and SC scores\n",
    "mordred_features = list(pd.read_csv('../reproduce_figure_3/ML_mordred_feature_list/12_iteration_feature_33_features.csv')['Name'].to_numpy()[1:]) # start with index 1 since we want to skip over emin which is the first (most important) feature\n",
    "score_names = ['smiles_1 sa_score','smiles_1 sc_score','smiles_1 ra_score','smiles_1 syba_score']\n",
    "run_type_names = ['mordred_smiles 1 ra_score','mordred_smiles 1 sc_score','mordred_smiles 1 ra_score','mordred_smiles 1 syba_score']\n",
    "\n",
    "data = pd.read_csv(f'../../Computing Mordred Features for QM9/qm9_mordred.csv',usecols=mordred_features + ['Reported'] + score_names + ['Emin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ML(training_features,training_labels,n_train):\n",
    "\n",
    "    model = RandomForestClassifier(n_jobs=-1)\n",
    "    # define training and testing based on splits\n",
    "    X_train, X_test, y_train, y_test = train_test_split(training_features,training_labels, train_size = n_train, stratify=training_labels)\n",
    "\n",
    "    # fit and predict\n",
    "    model.fit(X_train,y_train)\n",
    "    y_predicted = model.predict_proba(X_test)\n",
    "    y_ground_truth = y_test\n",
    "    \n",
    "    return y_predicted, y_ground_truth\n",
    "\n",
    "def perform_ML_for_feature_set(feature_names,run_type):\n",
    "    training_features = data[feature_names].to_numpy()\n",
    "    training_labels = data['Reported'].to_numpy()\n",
    "\n",
    "    # scramble ordering of features and labels to get a more homogeneously distributed dataset\n",
    "    np.random.seed(123) # do not change this seed from 123\n",
    "    scramble_indices = np.random.choice(range(len(training_labels)),size=len(training_labels),replace=False)\n",
    "\n",
    "    training_features = training_features[scramble_indices]\n",
    "    training_labels = training_labels[scramble_indices]\n",
    "\n",
    "    df_data = defaultdict(list)\n",
    "\n",
    "    for n_train in tqdm(n_train_sizes,desc=\"Train Size\", position=0,leave=True):\n",
    "\n",
    "        df_data['Training Size'] += [n_train]\n",
    "\n",
    "        for trial in tqdm(range(n_trials),desc=\"Trial\", position=1,leave=False):\n",
    "            y_predicted, y_ground_truth = run_ML(training_features,training_labels,n_train)\n",
    "\n",
    "            roc_auc = roc_auc_score(y_ground_truth,y_predicted[:,1])\n",
    "\n",
    "            df_data[f'Trial {trial+1}'] += [roc_auc]\n",
    "\n",
    "    results = pd.DataFrame(data = df_data)\n",
    "    trials_mask = results.columns.str.contains('Trial*')\n",
    "    trials_data = results.loc[:,trials_mask].to_numpy()\n",
    "    results['Mean AUC'] = np.mean(trials_data,axis=1)\n",
    "    results['Std AUC'] = np.std(trials_data,axis=1)\n",
    "    results.to_csv(f'results_{run_type}.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_sizes = [50,250,1250,6250,31250,100000]\n",
    "n_trials = 30\n",
    "\n",
    "for i in range(len(score_names)):\n",
    "    score = score_names[i]\n",
    "        \n",
    "    if i == 0: perform_ML_for_feature_set(mordred_features,'mordred') # only need to run this once\n",
    "    perform_ML_for_feature_set([score] + mordred_features,f'mordred_{score}')\n",
    "    perform_ML_for_feature_set(['Emin'] + [score] + mordred_features,f'mordred_emin_{score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot all 4 subplots for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, sharex=True, sharey=True, figsize=(15, 3))\n",
    "ax1 = plt.subplot(1, 4, 1)\n",
    "all_results_1 = ['results_mordred_emin_smiles_1 sa_score.csv','results_mordred_smiles_1 sa_score.csv','results_mordred.csv']\n",
    "all_labels_1 = [r'Mordred + SA + $E_{min}$', 'Mordred + SA', 'Mordred']\n",
    "ax2 = plt.subplot(1, 4, 2)\n",
    "all_results_2 = ['results_mordred_emin_smiles_1 sc_score.csv','results_mordred_smiles_1 sc_score.csv','results_mordred.csv']\n",
    "all_labels_2 = [r'Mordred + SC + $E_{min}$', 'Mordred + SC', 'Mordred']\n",
    "ax3 = plt.subplot(1, 4, 3)\n",
    "all_results_3 = ['results_mordred_emin_smiles_1 syba_score.csv','results_mordred_smiles_1 syba_score.csv','results_mordred.csv']\n",
    "all_labels_3 = ['Mordred + SYBA + $E_{min}$', 'Mordred + SYBA', 'Mordred']\n",
    "ax4 = plt.subplot(1, 4, 4)\n",
    "all_results_4 = ['results_mordred_emin_smiles_1 ra_score.csv','results_mordred_smiles_1 ra_score.csv','results_mordred.csv']\n",
    "all_labels_4 = ['Mordred + RA + $E_{min}$', 'Mordred + RA', 'Mordred']\n",
    "\n",
    "axs = [ax1,ax2,ax3,ax4]\n",
    "all_results_list = [all_results_1,all_results_2,all_results_3,all_results_4]\n",
    "all_labels_list = [all_labels_1,all_labels_2,all_labels_3,all_labels_4]\n",
    "\n",
    "score_names_title = ['SA Score','SC Score','SYBA Score','RA Score']\n",
    "\n",
    "\n",
    "for j in range(4): # 4 plots total\n",
    "    \n",
    "    all_results = all_results_list[j]\n",
    "    all_labels = all_labels_list[j]\n",
    "    subplot = axs[j]\n",
    "    \n",
    "    for i in range(len(all_results)):\n",
    "        results = pd.read_csv(all_results[i])\n",
    "        label = all_results[i]\n",
    "        subplot.errorbar(results['Training Size'], results['Mean AUC'], yerr = results['Std AUC'].to_numpy(),marker='d',label=all_labels[i],capsize=5,alpha=0.7)\n",
    "        subplot.set_xscale('log')\n",
    "        ax1.set_ylabel('ROC AUC')\n",
    "        subplot.legend(loc='lower right')\n",
    "        subplot.set_xlabel('Training Set Size')\n",
    "        subplot.set_title(score_names_title[j])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d97570bacec7fd5be4af27e1255edf48f45d2285fbfe7cdaecfe9946c7652b1c"
  },
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "my-rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
